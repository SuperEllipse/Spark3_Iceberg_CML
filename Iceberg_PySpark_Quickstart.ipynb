{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "private-diversity",
   "metadata": {},
   "source": [
    "# Using Apache Iceberg with Spark 3 in CML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-silly",
   "metadata": {},
   "source": [
    "The official documentation for Apache Iceberg with Spark is located at [this link](https://iceberg.apache.org/#getting-started/#using-iceberg-in-spark-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-burns",
   "metadata": {},
   "source": [
    "For a full list of Apache Iceberg terms, please visit [this link](https://iceberg.apache.org/#terms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-committee",
   "metadata": {},
   "source": [
    "### Start a PySpark Session as shown below. You will want to set the Spark Catalog configurations as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incomplete-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]') \\\n",
    "  .config(\"spark.jars.packages\",\"org.apache.iceberg:iceberg-spark3-runtime:0.12.1\") \\\n",
    "  .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-level",
   "metadata": {},
   "source": [
    "### Iceberg comes with catalogs that enable SQL commands to manage tables and load them by name. \n",
    "### Catalogs are configured using properties under spark.sql.catalog.(catalog_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|   testdb|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # Using a local Spark Catalog\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_catalog.testdb \")\n",
    "spark.sql(\"USE spark_catalog.testdb\")\n",
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()\n",
    "#spark.sql(\"DROP TABLE testtable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-immune",
   "metadata": {},
   "source": [
    "### You can use simple Spark SQL commands to create Spark tables as you always have. Just make sure to specify the USING iceberg clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS testtable (id bigint, data string) USING iceberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-pickup",
   "metadata": {},
   "source": [
    "### To select a specific table snapshot or the snapshot at some time, Iceberg supports two Spark read options:\n",
    "\n",
    "* snapshot-id selects a specific table snapshot\n",
    "* as-of-timestamp selects the current snapshot at a timestamp, in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-definition",
   "metadata": {},
   "source": [
    "#### You can view all snapshots associated with the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "future-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                                       |summary                                                                                                                                                                                                                                                                                           |\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2021-11-19 10:08:15.886|3492322305412256778|null               |append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3492322305412256778-1-be901a2e-e857-4b22-b830-737c79bb87bb.avro|{spark.app.id -> local-1637314257373, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 3, total-files-size -> 628, total-data-files -> 1, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}    |\n",
      "|2021-11-19 10:21:55.566|107550928418073495 |3492322305412256778|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-107550928418073495-1-b2ad9317-f3b0-4fbf-b63e-71afb9b17c3d.avro |{spark.app.id -> local-1637314257373, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 6, total-files-size -> 1256, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2021-11-19 10:28:30.292|1545408577715836429|107550928418073495 |append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-1545408577715836429-1-8879a83c-8440-474f-b440-be95b4384fa2.avro|{spark.app.id -> local-1637314257373, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 9, total-files-size -> 1884, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2021-11-19 10:28:33.014|2649908378426818566|1545408577715836429|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-2649908378426818566-1-445e1639-2939-4071-b6ec-c444f80ee8aa.avro|{spark.app.id -> local-1637314257373, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 12, total-files-size -> 2512, total-data-files -> 4, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2021-11-19 10:34:33.135|3533974690975069464|2649908378426818566|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3533974690975069464-1-0ae8f40f-9560-4b46-8b10-805de6e02db1.avro|{spark.app.id -> local-1637317760667, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 15, total-files-size -> 3140, total-data-files -> 5, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2021-11-20 00:32:49.144|3355558037703162022|3533974690975069464|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3355558037703162022-1-3803fb17-c221-4cc5-9679-d57f8e21dd62.avro|{spark.app.id -> local-1637368179620, added-data-files -> 2, added-records -> 3, added-files-size -> 1245, changed-partition-count -> 1, total-records -> 18, total-files-size -> 4385, total-data-files -> 7, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2021-11-20 00:33:28.398|3383995530425746467|3355558037703162022|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3383995530425746467-1-6e963cb3-59b4-474f-9154-f8f920ccaf19.avro|{spark.app.id -> local-1637368179620, added-data-files -> 2, added-records -> 3, added-files-size -> 1245, changed-partition-count -> 1, total-records -> 21, total-files-size -> 5630, total-data-files -> 9, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2021-11-20 01:15:01.931|4072529096957210655|3383995530425746467|append   |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-4072529096957210655-1-30abaa14-3bd0-4b4f-bd9b-65431d40d90d.avro|{spark.app.id -> local-1637368179620, added-data-files -> 2, added-records -> 3, added-files-size -> 1245, changed-partition-count -> 1, total-records -> 24, total-files-size -> 6875, total-data-files -> 11, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+-----------------------+-------------------+-------------------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.snapshots\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-place",
   "metadata": {},
   "source": [
    "#### Or a full table version history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adequate-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2021-11-19 10:08:15.886|3492322305412256778|null               |true               |\n",
      "|2021-11-19 10:21:55.566|107550928418073495 |3492322305412256778|true               |\n",
      "|2021-11-19 10:28:30.292|1545408577715836429|107550928418073495 |true               |\n",
      "|2021-11-19 10:28:33.014|2649908378426818566|1545408577715836429|true               |\n",
      "|2021-11-19 10:34:33.135|3533974690975069464|2649908378426818566|true               |\n",
      "|2021-11-20 00:32:49.144|3355558037703162022|3533974690975069464|true               |\n",
      "|2021-11-20 00:33:28.398|3383995530425746467|3355558037703162022|true               |\n",
      "|2021-11-20 01:15:01.931|4072529096957210655|3383995530425746467|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.history\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-active",
   "metadata": {},
   "source": [
    "#### To show a table’s data files and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excessive-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|content|file_path                                                                                                                              |file_format|record_count|file_size_in_bytes|column_sizes      |value_counts    |null_value_counts|nan_value_counts|lower_bounds           |upper_bounds           |key_metadata|split_offsets|equality_ids|\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-20-5b71b08a-00e9-4945-b294-4cb416ecf53f-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-21-8c99dd06-4769-4165-bfe5-b7b949a6a5ee-00001.parquet|PARQUET    |2           |623               |{1 -> 49, 2 -> 51}|{1 -> 2, 2 -> 2}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-14-4a8631ef-b874-4d72-8d91-eb29c7af25ae-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-15-d9e1169d-6e8c-45ad-80c2-b8973aecc38a-00001.parquet|PARQUET    |2           |623               |{1 -> 49, 2 -> 51}|{1 -> 2, 2 -> 2}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-9-0be0d3f3-143f-4ab3-9af7-9371ecb9b252-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-10-a66e72c1-eda8-4c23-9312-2f896bb17e2d-00001.parquet|PARQUET    |2           |623               |{1 -> 49, 2 -> 51}|{1 -> 2, 2 -> 2}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-3-5a8209ad-e336-4a04-a379-4fc3fb5cb4ce-00001.parquet |PARQUET    |3           |628               |{1 -> 51, 2 -> 54}|{1 -> 3, 2 -> 3}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-24-8010e40a-231b-4659-a6c1-98e8a89e0c37-00001.parquet|PARQUET    |3           |628               |{1 -> 51, 2 -> 54}|{1 -> 3, 2 -> 3}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> c}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-20-d480ba2a-48e5-455d-9215-9f1306dec05b-00001.parquet|PARQUET    |3           |628               |{1 -> 51, 2 -> 54}|{1 -> 3, 2 -> 3}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> c}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-19-5d6b9619-9d93-4a6f-8809-ec68e66f446a-00001.parquet|PARQUET    |3           |628               |{1 -> 51, 2 -> 54}|{1 -> 3, 2 -> 3}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> c}|null        |[4]          |null        |\n",
      "|0      |s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-15-8838e68a-9b6a-4f49-b306-4e3335d9d2bf-00001.parquet|PARQUET    |3           |628               |{1 -> 51, 2 -> 54}|{1 -> 3, 2 -> 3}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> a}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> c}|null        |[4]          |null        |\n",
      "+-------+---------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.files\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-brooklyn",
   "metadata": {},
   "source": [
    "### A manifest file is a metadata file that lists a subset of data files that make up a snapshot.\n",
    "\n",
    "### Each data file in a manifest is stored with a partition tuple, column-level stats, and summary information used to prune splits during scan planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-participant",
   "metadata": {},
   "source": [
    "#### To show a table’s file manifests and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|path                                                                                                                        |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|partition_summaries|\n",
      "+----------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/30abaa14-3bd0-4b4f-bd9b-65431d40d90d-m0.avro|5650  |0                |4072529096957210655|2                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/6e963cb3-59b4-474f-9154-f8f920ccaf19-m0.avro|5650  |0                |3383995530425746467|2                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/3803fb17-c221-4cc5-9679-d57f8e21dd62-m0.avro|5658  |0                |3355558037703162022|2                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/0ae8f40f-9560-4b46-8b10-805de6e02db1-m0.avro|5593  |0                |3533974690975069464|1                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/445e1639-2939-4071-b6ec-c444f80ee8aa-m0.avro|5592  |0                |2649908378426818566|1                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/8879a83c-8440-474f-b440-be95b4384fa2-m0.avro|5595  |0                |1545408577715836429|1                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/b2ad9317-f3b0-4fbf-b63e-71afb9b17c3d-m0.avro|5592  |0                |107550928418073495 |1                     |0                        |0                       |[]                 |\n",
      "|s3a://gd01-uat2/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/be901a2e-e857-4b22-b830-737c79bb87bb-m0.avro|5594  |0                |3492322305412256778|1                     |0                        |0                       |[]                 |\n",
      "+----------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.manifests\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-smith",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-laser",
   "metadata": {},
   "source": [
    "### Using snapshots as shown above, we can insert some data into the table and roll back to its original state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "present-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO testtable VALUES (1, 'x'), (2, 'y'), (3, 'z')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faced-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using select\n",
    "spark.sql(\"SELECT * FROM testtable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "useful-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using DF - All Data\n",
    "df = spark.table(\"spark_catalog.testdb.testtable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "subtle-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp = 1638410067.273329\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp = datetime.timestamp(now)\n",
    "print(\"timestamp =\", timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-commerce",
   "metadata": {},
   "source": [
    "#### Timestamps can be tricky. Please make sure to round your timestamp as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expanded-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   a|\n",
      "|  2|   b|\n",
      "|  3|   c|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"spark_catalog.testdb.testtable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "parallel-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO testtable VALUES (1, 'd'), (2, 'e'), (3, 'f')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
