{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "private-diversity",
   "metadata": {},
   "source": [
    "# Using Apache Iceberg with Spark 3 in CML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-silly",
   "metadata": {},
   "source": [
    "The official documentation for Apache Iceberg with Spark is located at [this link](https://iceberg.apache.org/#getting-started/#using-iceberg-in-spark-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-burns",
   "metadata": {},
   "source": [
    "For a full list of Apache Iceberg terms, please visit [this link](https://iceberg.apache.org/#terms/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-committee",
   "metadata": {},
   "source": [
    "### Start a PySpark Session as shown below. You will want to set the Spark Catalog configurations as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incomplete-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]') \\\n",
    "  .config(\"spark.jars.packages\",\"org.apache.iceberg:iceberg-spark3-runtime:0.12.1\") \\\n",
    "  .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "  .getOrCreate()\"\"\"\n",
    "\n",
    "\"\"\"SimpleApp.py\"\"\"\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "  .appName(\"1.1 - Ingest\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\", \"us-east-2\")\\\n",
    "  .config(\"spark.yarn.access.hadoopFileSystems\", \"s3a://demo-aws-go02\")\\\n",
    "  .config(\"spark.jars\",\"/home/cdsw/lib/iceberg-spark3-runtime-0.9.1.1.13.317211.0-9.jar\") \\\n",
    "  .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-level",
   "metadata": {},
   "source": [
    "### Iceberg comes with catalogs that enable SQL commands to manage tables and load them by name. \n",
    "### Catalogs are configured using properties under spark.sql.catalog.(catalog_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|      catalog|namespace|\n",
      "+-------------+---------+\n",
      "|spark_catalog|   testdb|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # Using a local Spark Catalog\n",
    "\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS spark_catalog.newjar\")\n",
    "spark.sql(\"USE spark_catalog.testdb\")\n",
    "spark.sql(\"SHOW CURRENT NAMESPACE\").show()\n",
    "#spark.sql(\"DROP TABLE testtable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-immune",
   "metadata": {},
   "source": [
    "### You can use simple Spark SQL commands to create Spark tables as you always have. Just make sure to specify the USING iceberg clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS newtesttable (id bigint, data string) USING iceberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-pickup",
   "metadata": {},
   "source": [
    "### To select a specific table snapshot or the snapshot at some time, Iceberg supports two Spark read options:\n",
    "\n",
    "* snapshot-id selects a specific table snapshot\n",
    "* as-of-timestamp selects the current snapshot at a timestamp, in milliseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-definition",
   "metadata": {},
   "source": [
    "#### You can view all snapshots associated with the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ec587b-605f-4a1c-9d42-292d02ed1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, data: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.newtesttable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "future-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id          |operation|manifest_list                                                                                                                                           |summary                                                                                                                                                                                                                                                                                            |\n",
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2022-02-17 18:25:41.503|3386067383611655633|null               |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3386067383611655633-1-88564820-fa3f-46d5-8329-01b01f85d416.avro|{spark.app.id -> local-1645122283239, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 3, total-files-size -> 628, total-data-files -> 1, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}     |\n",
      "|2022-02-17 18:25:47.601|555494963528835889 |3386067383611655633|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-555494963528835889-1-93c5905c-2d2d-442a-b434-34d8d966eef5.avro |{spark.app.id -> local-1645122283239, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 6, total-files-size -> 1256, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}    |\n",
      "|2022-02-17 18:26:26.741|6919659684029084940|555494963528835889 |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-6919659684029084940-1-00f41b8d-69fe-4280-b400-081ce0f67d3a.avro|{spark.app.id -> local-1645122283239, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 9, total-files-size -> 1884, total-data-files -> 3, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}    |\n",
      "|2022-02-17 18:50:33.923|7094097289391594974|6919659684029084940|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-7094097289391594974-1-e5b65f6d-a89e-4b35-bca3-75eb92818358.avro|{spark.app.id -> local-1645122283239, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 12, total-files-size -> 2512, total-data-files -> 4, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2022-02-17 18:51:14.966|4337728976320510621|7094097289391594974|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-4337728976320510621-1-eb85cb70-e545-4691-8587-6c5aa0381867.avro|{spark.app.id -> local-1645122283239, added-data-files -> 1, added-records -> 3, added-files-size -> 628, changed-partition-count -> 1, total-records -> 15, total-files-size -> 3140, total-data-files -> 5, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}   |\n",
      "|2022-02-27 21:27:55.773|81890142028154896  |4337728976320510621|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-81890142028154896-1-af60cff4-db0e-43bb-a3bc-07e77268e1b4.avro  |{spark.app.id -> local-1645996883695, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 18, total-files-size -> 5006, total-data-files -> 8, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}  |\n",
      "|2022-02-27 21:29:02.726|3184551259780646899|81890142028154896  |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3184551259780646899-1-9f2684b8-a03d-4e14-afc5-cbace881ad8d.avro|{spark.app.id -> local-1645996883695, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 21, total-files-size -> 6872, total-data-files -> 11, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-02-27 22:52:34.715|6113538126025083294|3184551259780646899|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-6113538126025083294-1-99463478-6a51-4d9a-ad39-f98c56a90391.avro|{spark.app.id -> local-1646002287602, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 24, total-files-size -> 8738, total-data-files -> 14, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0} |\n",
      "|2022-02-27 22:52:41.881|330895133654850392 |6113538126025083294|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-330895133654850392-1-35877bba-ec6e-400f-8e2b-b109a3af0cbb.avro |{spark.app.id -> local-1646002287602, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 27, total-files-size -> 10604, total-data-files -> 17, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-02-27 23:31:46.232|9144498560785472969|330895133654850392 |append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-9144498560785472969-1-e38b8515-3755-4835-86c3-6aa757619a76.avro|{spark.app.id -> local-1646004653395, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 30, total-files-size -> 12470, total-data-files -> 20, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-02-27 23:31:54.872|4914989311975181376|9144498560785472969|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-4914989311975181376-1-cdcdb9fe-4cb9-4850-a5cf-3dfc8797aa75.avro|{spark.app.id -> local-1646004653395, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 33, total-files-size -> 14336, total-data-files -> 23, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-02-28 00:03:13.178|6844056686025795516|4914989311975181376|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-6844056686025795516-1-b00deb12-df3d-4a30-ae25-ad6c78e66223.avro|{spark.app.id -> local-1646006544416, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 36, total-files-size -> 16202, total-data-files -> 26, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-02-28 00:03:23.131|7657248862488654272|6844056686025795516|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-7657248862488654272-1-febd55c6-662a-4086-8391-f2ba067bdebc.avro|{spark.app.id -> local-1646006544416, added-data-files -> 3, added-records -> 3, added-files-size -> 1866, changed-partition-count -> 1, total-records -> 39, total-files-size -> 18068, total-data-files -> 29, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-03-02 18:17:10.91 |3950113239958340238|7657248862488654272|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-3950113239958340238-1-3fcf5dfa-62b5-49f1-852e-2402283fe049.avro|{spark.app.id -> local-1646244989278, added-data-files -> 2, added-records -> 3, added-files-size -> 1245, changed-partition-count -> 1, total-records -> 42, total-files-size -> 19313, total-data-files -> 31, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "|2022-03-02 18:17:22.172|333250371788972430 |3950113239958340238|append   |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/snap-333250371788972430-1-b4aceee5-0e2f-4d85-a47f-6c24de143bdd.avro |{spark.app.id -> local-1646244989278, added-data-files -> 2, added-records -> 3, added-files-size -> 1245, changed-partition-count -> 1, total-records -> 45, total-files-size -> 20558, total-data-files -> 33, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+-----------------------+-------------------+-------------------+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.snapshots\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-place",
   "metadata": {},
   "source": [
    "#### Or a full table version history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2022-02-17 18:25:41.503|3386067383611655633|null               |true               |\n",
      "|2022-02-17 18:25:47.601|555494963528835889 |3386067383611655633|true               |\n",
      "|2022-02-17 18:26:26.741|6919659684029084940|555494963528835889 |true               |\n",
      "|2022-02-17 18:50:33.923|7094097289391594974|6919659684029084940|true               |\n",
      "|2022-02-17 18:51:14.966|4337728976320510621|7094097289391594974|true               |\n",
      "|2022-02-27 21:27:55.773|81890142028154896  |4337728976320510621|true               |\n",
      "|2022-02-27 21:29:02.726|3184551259780646899|81890142028154896  |true               |\n",
      "|2022-02-27 22:52:34.715|6113538126025083294|3184551259780646899|true               |\n",
      "|2022-02-27 22:52:41.881|330895133654850392 |6113538126025083294|true               |\n",
      "|2022-02-27 23:31:46.232|9144498560785472969|330895133654850392 |true               |\n",
      "|2022-02-27 23:31:54.872|4914989311975181376|9144498560785472969|true               |\n",
      "|2022-02-28 00:03:13.178|6844056686025795516|4914989311975181376|true               |\n",
      "|2022-02-28 00:03:23.131|7657248862488654272|6844056686025795516|true               |\n",
      "|2022-03-02 18:17:10.91 |3950113239958340238|7657248862488654272|true               |\n",
      "|2022-03-02 18:17:22.172|333250371788972430 |3950113239958340238|true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.history\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-active",
   "metadata": {},
   "source": [
    "#### To show a table’s data files and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excessive-hawaiian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|content|file_path                                                                                                                                  |file_format|record_count|file_size_in_bytes|column_sizes      |value_counts    |null_value_counts|nan_value_counts|lower_bounds           |upper_bounds           |key_metadata|split_offsets|equality_ids|\n",
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-9-81b48202-21c5-4a8d-b461-e2990273dc39-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-10-086f90bc-7727-4b8f-ac2d-ccd61af62988-00001.parquet|PARQUET    |2           |623               |{1 -> 49, 2 -> 51}|{1 -> 2, 2 -> 2}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-4-e1b83b9d-a481-4356-be54-dc319c38262c-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-5-dfbe426e-0b2a-4692-943e-e27d889fae88-00001.parquet |PARQUET    |2           |623               |{1 -> 49, 2 -> 51}|{1 -> 2, 2 -> 2}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-11-38071e8a-e274-42a8-8a81-052fad57abd1-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-12-8e8125cd-7a94-4078-a437-75cca91bb63b-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00002-13-401e5db0-6f18-4a11-8315-d09ed936c38b-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-5-5d8cc5a6-9b4a-4689-b72c-f1e388d03d7d-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-6-c0b5f48c-6997-46af-a273-6a96d8b88080-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00002-7-6d448567-0826-4c93-acec-db99af31cc7c-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-11-04f21df2-1c0f-46eb-adcf-f2aab148ce60-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-12-a888a4f4-38c2-4744-83f0-bf9d9a59a9e7-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00002-13-b747111d-d9ec-4938-8231-6588a94cd5a5-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-5-03d2f1b6-4597-4603-8830-ad301d0e0c3f-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-6-b63dd193-5e44-4163-b7aa-c5d078ec56b9-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> y}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00002-7-58b307d5-6461-4cca-8fde-212a5982cd47-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> z}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-10-abd4c42d-d146-4aa8-bb32-b337ecc2a651-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> d}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00001-11-88f17ac7-19ef-4a4b-85dd-c7a9d38e9b56-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|{1 -> \u0002\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> e}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00002-12-c01e01f5-3052-429e-b9ac-b2e8ee09cc0d-00001.parquet|PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|{1 -> \u0003\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> f}|null        |[4]          |null        |\n",
      "|0      |s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/data/00000-4-b5497779-516d-4c15-b4a4-f6c8c0397194-00001.parquet |PARQUET    |1           |622               |{1 -> 46, 2 -> 48}|{1 -> 1, 2 -> 1}|{1 -> 0, 2 -> 0} |{}              |{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|{1 -> \u0001\u0000\u0000\u0000\u0000\u0000\u0000\u0000, 2 -> x}|null        |[4]          |null        |\n",
      "+-------+-------------------------------------------------------------------------------------------------------------------------------------------+-----------+------------+------------------+------------------+----------------+-----------------+----------------+-----------------------+-----------------------+------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.files\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-brooklyn",
   "metadata": {},
   "source": [
    "### A manifest file is a metadata file that lists a subset of data files that make up a snapshot.\n",
    "\n",
    "### Each data file in a manifest is stored with a partition tuple, column-level stats, and summary information used to prune splits during scan planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-participant",
   "metadata": {},
   "source": [
    "#### To show a table’s file manifests and each file’s metadata, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solid-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|path                                                                                                                            |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|partition_summaries|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/b4aceee5-0e2f-4d85-a47f-6c24de143bdd-m0.avro|5658  |0                |333250371788972430 |2                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/3fcf5dfa-62b5-49f1-852e-2402283fe049-m0.avro|5655  |0                |3950113239958340238|2                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/febd55c6-662a-4086-8391-f2ba067bdebc-m0.avro|5676  |0                |7657248862488654272|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/b00deb12-df3d-4a30-ae25-ad6c78e66223-m0.avro|5679  |0                |6844056686025795516|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/cdcdb9fe-4cb9-4850-a5cf-3dfc8797aa75-m0.avro|5680  |0                |4914989311975181376|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/e38b8515-3755-4835-86c3-6aa757619a76-m0.avro|5680  |0                |9144498560785472969|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/35877bba-ec6e-400f-8e2b-b109a3af0cbb-m0.avro|5677  |0                |330895133654850392 |3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/99463478-6a51-4d9a-ad39-f98c56a90391-m0.avro|5678  |0                |6113538126025083294|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/9f2684b8-a03d-4e14-afc5-cbace881ad8d-m0.avro|5674  |0                |3184551259780646899|3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/af60cff4-db0e-43bb-a3bc-07e77268e1b4-m0.avro|5674  |0                |81890142028154896  |3                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/eb85cb70-e545-4691-8587-6c5aa0381867-m0.avro|5599  |0                |4337728976320510621|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/e5b65f6d-a89e-4b35-bca3-75eb92818358-m0.avro|5600  |0                |7094097289391594974|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/00f41b8d-69fe-4280-b400-081ce0f67d3a-m0.avro|5600  |0                |6919659684029084940|1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/93c5905c-2d2d-442a-b434-34d8d966eef5-m0.avro|5599  |0                |555494963528835889 |1                     |0                        |0                       |[]                 |\n",
      "|s3a://demo-aws-go02/warehouse/tablespace/external/hive/testdb.db/testtable/metadata/88564820-fa3f-46d5-8329-01b01f85d416-m0.avro|5599  |0                |3386067383611655633|1                     |0                        |0                       |[]                 |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"iceberg\").load(\"spark_catalog.testdb.testtable.manifests\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-smith",
   "metadata": {},
   "source": [
    "## Time Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-laser",
   "metadata": {},
   "source": [
    "### Using snapshots as shown above, we can insert some data into the table and roll back to its original state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "present-venezuela",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO spark_catalog.testdb.testtable VALUES (1, 'x'), (2, 'y'), (3, 'z')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faced-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using select\n",
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.testtable\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "useful-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using DF - All Data\n",
    "df = spark.table(\"spark_catalog.testdb.testtable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subtle-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp = 1646334004.441659\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp = datetime.timestamp(now)\n",
    "print(\"timestamp =\", timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-commerce",
   "metadata": {},
   "source": [
    "#### Timestamps can be tricky. Please make sure to round your timestamp as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expanded-neighbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using a point in time\n",
    "df = spark.read.option(\"as-of-timestamp\", int(timestamp*1000)).format(\"iceberg\").load(\"spark_catalog.testdb.testtable\")\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "parallel-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert using Iceberg format\n",
    "spark.sql(\"INSERT INTO spark_catalog.testdb.testtable VALUES (1, 'd'), (2, 'e'), (3, 'f')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d35f7a32-7e20-41cd-9793-a963100eeac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.writeTo(\"spark_catalog.testdb.testtablethree\").create()\n",
    "\n",
    "#df.write.format(\"iceberg\").mode(\"overwrite\").save(\"testdb.testtabletwo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8ed0ea-0c77-4878-9ac7-62f00b3bf34d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot write into v1 table: `testdb`.`testtabletwo`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-48a1e9d45293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark_catalog.testdb.testtabletwo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0mAppend\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mframe\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \"\"\"\n\u001b[0;32m-> 1563\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot write into v1 table: `testdb`.`testtabletwo`"
     ]
    }
   ],
   "source": [
    "df.writeTo(\"spark_catalog.testdb.testtabletwo\").append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e5621db-65e2-47c4-a3a9-e3422b780c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|data|\n",
      "+---+----+\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "|  3|   z|\n",
      "|  1|   d|\n",
      "|  2|   e|\n",
      "|  3|   f|\n",
      "|  1|   x|\n",
      "|  2|   y|\n",
      "+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query using select\n",
    "spark.sql(\"SELECT * FROM spark_catalog.testdb.testtablethree\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3fef11-e562-41c9-a94a-61bcd189d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "#Extracting the correct URL from hive-site.xml\n",
    "tree = ET.parse('/etc/hadoop/conf/hive-site.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "for prop in root.findall('property'):\n",
    "    if prop.find('name').text == \"hive.metastore.warehouse.dir\":\n",
    "        storage = prop.find('value').text.split(\"/\")[0] + \"//\" + prop.find('value').text.split(\"/\")[2]\n",
    "\n",
    "print(\"The correct CLoud Storage URL is:{}\".format(storage))\n",
    "\n",
    "os.environ['STORAGE'] = storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b64d5-efa1-44a9-926f-3d5a2f42175e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedad12-7ef6-4f8c-9ced-c78c37df5f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887806e-a45c-472b-bc13-22b037469244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
